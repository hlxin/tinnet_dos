{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4313b5b9",
   "metadata": {},
   "source": [
    "Hyperparameter optimization for TinNet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af46bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading modules\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from ase import io\n",
    "from ase.db import connect\n",
    "\n",
    "from tinnet.regression.regression import Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc41521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "\n",
    "class TrainTinNet(tune.Trainable):\n",
    "    def _setup(self, config):\n",
    "        \n",
    "        self.lr = config.get('lr', 0.01)\n",
    "        self.atom_fea_len = int(config.get('atom_fea_len', 64))\n",
    "        self.n_conv = int(config.get('n_conv', 3))\n",
    "        self.h_fea_len = int(config.get('h_fea_len', 128))\n",
    "        self.n_h = int(config.get('n_h', 1))\n",
    "        \n",
    "        db = connect('../Database.db')\n",
    "        \n",
    "        d_cen = []\n",
    "        full_width = []\n",
    "        tabulated_d_cen_inf = []\n",
    "        tabulated_full_width_inf = []\n",
    "        tabulated_mulliken = []\n",
    "        tabulated_site_index = []\n",
    "        tabulated_v2dd = []\n",
    "        tabulated_v2ds = []\n",
    "        atom_fea = []\n",
    "        nbr_fea = []\n",
    "        nbr_fea_idx = []\n",
    "        tabulated_padding_fillter = []\n",
    "        \n",
    "        for r in db.select():\n",
    "            d_cen += [r['data']['d_cen']]\n",
    "            full_width += [r['data']['full_width']]\n",
    "            tabulated_d_cen_inf += [r['data']['tabulated_d_cen_inf']]\n",
    "            tabulated_full_width_inf += [r['data']['tabulated_full_width_inf']]\n",
    "            tabulated_mulliken += [r['data']['tabulated_mulliken']]\n",
    "            tabulated_site_index += [r['data']['tabulated_site_index']]\n",
    "            tabulated_v2dd += [r['data']['tabulated_v2dd']]\n",
    "            tabulated_v2ds += [r['data']['tabulated_v2ds']]\n",
    "            atom_fea += [np.array(r['data']['atom_fea'], dtype=np.float32)]\n",
    "            nbr_fea += [np.array(r['data']['nbr_fea'], dtype=np.float32)]\n",
    "            nbr_fea_idx += [np.array(r['data']['nbr_fea_idx'], dtype=np.float32)]\n",
    "            tabulated_padding_fillter += [np.array(r['data']['tabulated_padding_fillter'], dtype=np.int32)]\n",
    "        \n",
    "        self.d_cen = np.array(d_cen, dtype=np.float32)\n",
    "        self.full_width = np.array(full_width, dtype=np.float32)\n",
    "        self.tabulated_d_cen_inf = np.array(tabulated_d_cen_inf, dtype=np.float32)\n",
    "        self.tabulated_full_width_inf = np.array(tabulated_full_width_inf, dtype=np.float32)\n",
    "        self.tabulated_mulliken = np.array(tabulated_mulliken, dtype=np.float32)\n",
    "        self.tabulated_site_index = np.array(tabulated_site_index, dtype=np.int32)\n",
    "        self.tabulated_v2dd = np.array(tabulated_v2dd, dtype=np.float32)\n",
    "        self.tabulated_v2ds = np.array(tabulated_v2ds, dtype=np.float32)\n",
    "        self.atom_fea = atom_fea\n",
    "        self.nbr_fea = nbr_fea\n",
    "        self.nbr_fea_idx = nbr_fea_idx\n",
    "        self.tabulated_padding_fillter = tabulated_padding_fillter\n",
    "    \n",
    "    def _train(self):\n",
    "        \n",
    "        self.model = Regression(self.atom_fea,\n",
    "                                self.nbr_fea,\n",
    "                                self.nbr_fea_idx,\n",
    "                                self.d_cen,\n",
    "                                phys_model='moment',\n",
    "                                optim_algorithm='AdamW',\n",
    "                                weight_decay=0.0001,\n",
    "                                idx_validation=0,\n",
    "                                idx_test=1,\n",
    "                                lr=self.lr,\n",
    "                                atom_fea_len=self.atom_fea_len,\n",
    "                                n_conv=self.n_conv,\n",
    "                                h_fea_len=self.h_fea_len,\n",
    "                                n_h=self.n_h,\n",
    "                                full_width=self.full_width,\n",
    "                                tabulated_d_cen_inf=self.tabulated_d_cen_inf,\n",
    "                                tabulated_padding_fillter=self.tabulated_padding_fillter,\n",
    "                                tabulated_full_width_inf=self.tabulated_full_width_inf,\n",
    "                                tabulated_mulliken=self.tabulated_mulliken,\n",
    "                                tabulated_site_index=self.tabulated_site_index,\n",
    "                                tabulated_v2dd=self.tabulated_v2dd,\n",
    "                                tabulated_v2ds=self.tabulated_v2ds,\n",
    "                                batch_size=64)\n",
    "        \n",
    "        final_ans_val_mae, \\\n",
    "        final_ans_val_mse,\\\n",
    "        final_ans_test_mae, \\\n",
    "        final_ans_test_mse \\\n",
    "                = self.model.train(25000)\n",
    "        \n",
    "        np.savetxt('final_ans_val_mae_'\n",
    "                   + str(self.lr)\n",
    "                   + '_'\n",
    "                   + str(self.atom_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_conv)\n",
    "                   + '_'\n",
    "                   + str(self.h_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_h)\n",
    "                   + '.txt', [final_ans_val_mae])\n",
    "        \n",
    "        np.savetxt('final_ans_val_mse_'\n",
    "                   + str(self.lr)\n",
    "                   + '_'\n",
    "                   + str(self.atom_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_conv)\n",
    "                   + '_'\n",
    "                   + str(self.h_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_h)\n",
    "                   + '.txt', [final_ans_val_mse])\n",
    "        \n",
    "        np.savetxt('final_ans_test_mae_'\n",
    "                   + str(self.lr)\n",
    "                   + '_'\n",
    "                   + str(self.atom_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_conv)\n",
    "                   + '_'\n",
    "                   + str(self.h_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_h)\n",
    "                   + '.txt', [final_ans_test_mae])\n",
    "        \n",
    "        np.savetxt('final_ans_test_mse_'\n",
    "                   + str(self.lr)\n",
    "                   + '_'\n",
    "                   + str(self.atom_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_conv)\n",
    "                   + '_'\n",
    "                   + str(self.h_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_h)\n",
    "                   + '.txt', [final_ans_test_mse])\n",
    "        \n",
    "        return {'mean_loss': final_ans_test_mse}\n",
    "\n",
    "    def _save(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, 'model.pth')\n",
    "        return checkpoint_path\n",
    "\n",
    "    def _restore(self, checkpoint_path):\n",
    "        self.model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    algo = BayesOptSearch(utility_kwargs={\n",
    "        'kind': 'ucb',\n",
    "        'kappa': 2.5,\n",
    "        'xi': 0.0\n",
    "    })\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=4)\n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    analysis = tune.run(\n",
    "        TrainTinNet,\n",
    "        name='TrainTinNet',\n",
    "        metric='mean_loss',\n",
    "        mode='min',\n",
    "        search_alg=algo,\n",
    "        scheduler=scheduler,\n",
    "        stop={\n",
    "            'mean_loss': 0.001,\n",
    "            'training_iteration': 20,\n",
    "        },\n",
    "        resources_per_trial={\n",
    "            'cpu': 12,\n",
    "            'gpu': 1\n",
    "        },\n",
    "        num_samples= 500,\n",
    "        checkpoint_at_end=True,\n",
    "        checkpoint_freq=20,\n",
    "        config={\n",
    "            'lr': tune.loguniform(lower=0.0010, upper=0.004, base=10),\n",
    "            'atom_fea_len': tune.uniform(lower=10, upper=206),\n",
    "            'n_conv': tune.uniform(lower=4, upper=11),\n",
    "            'h_fea_len': tune.uniform(lower=10, upper=101),\n",
    "            'n_h': tune.uniform(lower=1, upper=5),\n",
    "        })\n",
    "    \n",
    "    print('Best config is:', analysis.get_best_config(metric='mean_loss',\n",
    "                                                      mode='min'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
