{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b68f0e",
   "metadata": {},
   "source": [
    "Hyperparameter optimization for GCNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c972fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading modules\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import multiprocessing\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from ase import io\n",
    "from ase.db import connect\n",
    "\n",
    "from tinnet.feature.voronoi import Voronoi\n",
    "from tinnet.regression.regression import Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019aa52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "\n",
    "class TrainGCNN(tune.Trainable):\n",
    "    def _setup(self, config):\n",
    "        \n",
    "        self.lr = config.get('lr', 0.01)\n",
    "        self.atom_fea_len = int(config.get('atom_fea_len', 64))\n",
    "        self.n_conv = int(config.get('n_conv', 3))\n",
    "        self.h_fea_len = int(config.get('h_fea_len', 128))\n",
    "        self.n_h = int(config.get('n_h', 1))\n",
    "        \n",
    "        descriptor = Voronoi(max_num_nbr=12,\n",
    "                             radius=8,\n",
    "                             dmin=0,\n",
    "                             step=0.2,\n",
    "                             dict_atom_fea=None)\n",
    "        \n",
    "        db = connect('../Database.db')\n",
    "        \n",
    "        images = np.array([r.toatoms() for r in db.select()])\n",
    "        \n",
    "        self.d_cen = np.array([r['data']['d_cen'] for r in db.select()], dtype=np.float32)\n",
    "        self.full_width = np.array([r['data']['full_width'] for r in db.select()], dtype=np.float32)\n",
    "        \n",
    "        self.features = multiprocessing.Pool().map(descriptor.feas, images)\n",
    "    \n",
    "    def _train(self):\n",
    "        \n",
    "        self.model = Regression(self.features,\n",
    "                                self.d_cen,\n",
    "                                phys_model='gcnn_multitask',\n",
    "                                optim_algorithm='AdamW',\n",
    "                                weight_decay=0.0001,\n",
    "                                idx_validation=0,\n",
    "                                idx_test=1,\n",
    "                                lr=self.lr,\n",
    "                                atom_fea_len=self.atom_fea_len,\n",
    "                                n_conv=self.n_conv,\n",
    "                                h_fea_len=self.h_fea_len,\n",
    "                                n_h=self.n_h,\n",
    "                                full_width=self.full_width,\n",
    "                                batch_size=64)\n",
    "        \n",
    "        final_ans_val_mae, final_ans_val_mse,\\\n",
    "            final_ans_test_mae, final_ans_test_mse\\\n",
    "                = self.model.train(25000)\n",
    "        \n",
    "        np.savetxt('final_ans_val_mae_'\n",
    "                   + str(self.lr)\n",
    "                   + '_'\n",
    "                   + str(self.atom_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_conv)\n",
    "                   + '_'\n",
    "                   + str(self.h_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_h)\n",
    "                   + '.txt', [final_ans_val_mae])\n",
    "        \n",
    "        np.savetxt('final_ans_val_mse_'\n",
    "                   + str(self.lr)\n",
    "                   + '_'\n",
    "                   + str(self.atom_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_conv)\n",
    "                   + '_'\n",
    "                   + str(self.h_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_h)\n",
    "                   + '.txt', [final_ans_val_mse])\n",
    "        \n",
    "        np.savetxt('final_ans_test_mae_'\n",
    "                   + str(self.lr)\n",
    "                   + '_'\n",
    "                   + str(self.atom_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_conv)\n",
    "                   + '_'\n",
    "                   + str(self.h_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_h)\n",
    "                   + '.txt', [final_ans_test_mae])\n",
    "        \n",
    "        np.savetxt('final_ans_test_mse_'\n",
    "                   + str(self.lr)\n",
    "                   + '_'\n",
    "                   + str(self.atom_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_conv)\n",
    "                   + '_'\n",
    "                   + str(self.h_fea_len)\n",
    "                   + '_'\n",
    "                   + str(self.n_h)\n",
    "                   + '.txt', [final_ans_test_mse])\n",
    "        \n",
    "        return {'mean_loss': final_ans_test_mse}\n",
    "    \n",
    "    def _save(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, 'model.pth')\n",
    "        torch.save(self.model.state_dict(), checkpoint_path)\n",
    "        return checkpoint_path\n",
    "\n",
    "    def _restore(self, checkpoint_path):\n",
    "        self.model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98054383",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    algo = BayesOptSearch(utility_kwargs={\n",
    "        'kind': 'ucb',\n",
    "        'kappa': 2.5,\n",
    "        'xi': 0.0\n",
    "    })\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=4)\n",
    "    scheduler = AsyncHyperBandScheduler()\n",
    "    \n",
    "    analysis = tune.run(\n",
    "        TrainGCNN,\n",
    "        name='TrainGCNN',\n",
    "        metric='mean_loss',\n",
    "        mode='min',\n",
    "        search_alg=algo,\n",
    "        scheduler=scheduler,\n",
    "        stop={\n",
    "            'mean_loss': 0.001,\n",
    "            'training_iteration': 20,\n",
    "        },\n",
    "        resources_per_trial={\n",
    "            'cpu': 12,\n",
    "            'gpu': 1\n",
    "        },\n",
    "        num_samples= 500,\n",
    "        checkpoint_at_end=True,\n",
    "        checkpoint_freq=20,\n",
    "        config={\n",
    "            'lr': tune.loguniform(lower=0.0005, upper=0.004, base=10),\n",
    "            'atom_fea_len': tune.uniform(lower=100, upper=256),\n",
    "            'n_conv': tune.uniform(lower=3, upper=7),\n",
    "            'h_fea_len': tune.uniform(lower=50, upper=156),\n",
    "            'n_h': tune.uniform(lower=1, upper=5),\n",
    "        })\n",
    "    \n",
    "    print('Best config is:', analysis.get_best_config(metric='mean_loss',\n",
    "                                                      mode='min'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
