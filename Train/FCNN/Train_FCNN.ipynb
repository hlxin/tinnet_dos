{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384fd504",
   "metadata": {},
   "source": [
    "Train FCNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading module\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from copy import deepcopy\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from ase.db import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "\n",
    "def get_train_val_test_loader(dataset,\n",
    "                              idx_validation=0,\n",
    "                              idx_test=None,\n",
    "                              collate_fn=default_collate,\n",
    "                              batch_size=64,\n",
    "                              num_workers=0,\n",
    "                              pin_memory=False,\n",
    "                              random_seed=None):\n",
    "    \n",
    "    indices = np.arange(len(dataset))[:-38]\n",
    "    tmp = np.arange(len(dataset))[-38:] # Last 38 images are pure metals\n",
    "    \n",
    "    if random_seed:\n",
    "        random.Random(random_seed).shuffle(indices)\n",
    "    else:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    kfold = np.array_split(indices,10)\n",
    "    \n",
    "    kfold_val = deepcopy(kfold[idx_validation])\n",
    "    \n",
    "    try:\n",
    "        kfold_test = deepcopy(kfold[idx_test])\n",
    "    except:\n",
    "        kfold_test = []\n",
    "    \n",
    "    kfold_train = deepcopy([kfold[i]\n",
    "                            for i in range(0,10)\n",
    "                            if i != idx_validation and i != idx_test])\n",
    "    \n",
    "    kfold_train = np.array([item for sl in kfold_train for item in sl])\n",
    "    \n",
    "    kfold_train = np.concatenate((kfold_train,tmp))\n",
    "    \n",
    "    if random_seed:\n",
    "        random.Random(random_seed).shuffle(kfold_train)\n",
    "    else:\n",
    "        random.shuffle(kfold_train)\n",
    "    \n",
    "    val_sampler = SubsetRandomSampler(deepcopy(kfold_val))\n",
    "    test_sampler = SubsetRandomSampler(deepcopy(kfold_test))\n",
    "    train_sampler = SubsetRandomSampler(deepcopy(kfold_train))\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                              sampler=train_sampler,\n",
    "                              num_workers=num_workers,\n",
    "                              collate_fn=collate_fn,\n",
    "                              pin_memory=pin_memory)\n",
    "    \n",
    "    val_loader = DataLoader(dataset, batch_size=12500,\n",
    "                            sampler=val_sampler,\n",
    "                            num_workers=num_workers,\n",
    "                            collate_fn=collate_fn,\n",
    "                            pin_memory=pin_memory)\n",
    "    \n",
    "    test_loader = DataLoader(dataset, batch_size=12500,\n",
    "                             sampler=test_sampler,\n",
    "                             num_workers=num_workers,\n",
    "                             collate_fn=collate_fn,\n",
    "                             pin_memory=pin_memory)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_feature, n_h, h_fea_len, n_output):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc_in = nn.Linear(n_feature, h_fea_len)\n",
    "        self.fc_in_softplus = nn.Softplus()\n",
    "        if n_h > 1:\n",
    "            self.fcs = nn.ModuleList([nn.Linear(h_fea_len, h_fea_len)\n",
    "                                      for _ in range(n_h-1)])\n",
    "            self.softpluses = nn.ModuleList([nn.Softplus()\n",
    "                                             for _ in range(n_h-1)])\n",
    "        self.fc_out = nn.Linear(h_fea_len, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        crys_fea = self.fc_in(x)\n",
    "        crys_fea = self.fc_in_softplus(crys_fea)\n",
    "        \n",
    "        if hasattr(self, 'fcs') and hasattr(self, 'softpluses'):\n",
    "            for fc, softplus in zip(self.fcs, self.softpluses):\n",
    "                crys_fea = softplus(fc(crys_fea))\n",
    "        \n",
    "        out = self.fc_out(crys_fea)\n",
    "        out = torch.stack((out[:,0], torch.nn.functional.softplus(out[:,1]))).T\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785955ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "\n",
    "final_ans_val_MAE = np.zeros((10,10))\n",
    "final_ans_val_MSE = np.zeros((10,10))\n",
    "final_ans_test_MAE = np.zeros((10,10))\n",
    "final_ans_test_MSE = np.zeros((10,10))\n",
    "\n",
    "for idx_val in range(0,10):\n",
    "    for idx_test in range(0,10):\n",
    "        \n",
    "        # Optimized hyperparameters\n",
    "        lr = 0.001050190043090246\n",
    "        n_h = 8\n",
    "        h_fea_len = 65\n",
    "        \n",
    "        random_seed = 1234    # reproducible\n",
    "        batch_size = 64\n",
    "        num_workers = 0\n",
    "        weight_decay = 0.0001\n",
    "        \n",
    "        collate_fn = default_collate\n",
    "        best_val_loss = 1e10\n",
    "        best_counter = 0\n",
    "        \n",
    "        db = connect('../Database.db')\n",
    "        \n",
    "        d_cen = np.array([r['data']['d_cen'] for r in db.select()])\n",
    "        full_width = np.array([r['data']['full_width'] for r in db.select()])\n",
    "        target = np.stack((d_cen,full_width)).T\n",
    "\n",
    "        v2ds = np.array([r['data']['tabulated_v2ds'] for r in db.select()])\n",
    "        v2dd = np.array([r['data']['tabulated_v2dd'] for r in db.select()])\n",
    "        mulliken = np.array([r['data']['tabulated_mulliken'] for r in db.select()])\n",
    "        d_cen_inf = np.array([r['data']['tabulated_d_cen_inf'] for r in db.select()])\n",
    "        full_width_inf = np.array([r['data']['tabulated_full_width_inf'] for r in db.select()])\n",
    "        fea = np.stack((np.sum((v2ds + v2dd), axis=1), mulliken, d_cen_inf, full_width_inf**2.0/12.0)).T\n",
    "        \n",
    "        idx = np.arange(len(target))\n",
    "        \n",
    "        idx_1 = idx[:-38]\n",
    "        idx_2 = idx[-38:] # Last 38 images are pure metals\n",
    "        \n",
    "        num = int(len(idx_1)*1.00) # % of database for training (1.00 means 100%)\n",
    "        np.random.seed(12345)\n",
    "        np.random.shuffle(idx_1)\n",
    "        \n",
    "        idx_1 = idx_1[0:num]\n",
    "        \n",
    "        idx = np.sort(np.concatenate((idx_1,idx_2)))\n",
    "        \n",
    "        np.savetxt('index.txt', idx)\n",
    "        \n",
    "        target = np.array([target[i] for i in idx])\n",
    "        \n",
    "        fea = np.array([fea[i] for i in idx])\n",
    "        \n",
    "        target = Variable(torch.Tensor(target))\n",
    "        fea = Variable(torch.Tensor(fea))\n",
    "        \n",
    "        name_images = np.arange(len(fea))\n",
    "        \n",
    "        dataset = [(torch.Tensor(fea[i]),\n",
    "                    name_images[i])\n",
    "                   for i in range(len(fea))]\n",
    "        \n",
    "        train_loader, val_loader, test_loader =\\\n",
    "            get_train_val_test_loader(dataset=dataset,\n",
    "                                      collate_fn=collate_fn,\n",
    "                                      batch_size=batch_size,\n",
    "                                      idx_validation=idx_val,\n",
    "                                      idx_test=idx_test,\n",
    "                                      num_workers=num_workers,\n",
    "                                      pin_memory=torch.cuda.is_available(),\n",
    "                                      random_seed=random_seed)\n",
    "        \n",
    "        net = Net(n_feature=fea.shape[-1], n_h=n_h, h_fea_len=h_fea_len, n_output=2).cuda()\n",
    "        optimizer = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_func = nn.MSELoss()\n",
    "        \n",
    "        for epoch in range(100000):\n",
    "            \n",
    "            # switch to train mode\n",
    "            net.train()\n",
    "            \n",
    "            for i, (input, batch_cif_ids) in enumerate(train_loader):\n",
    "                prediction = net(input.cuda(non_blocking=True))\n",
    "                # loss must be (1. nn output, 2. target)\n",
    "                loss = loss_func(prediction, target[batch_cif_ids].cuda(non_blocking=True))\n",
    "                train_loss = torch.mean(torch.abs(target[batch_cif_ids].cuda(non_blocking=True) - prediction))*prediction.shape[-1]\n",
    "                optimizer.zero_grad()   # clear gradients for next train\n",
    "                loss.backward()         # backpropagation, compute gradients\n",
    "                optimizer.step()        # apply gradients\n",
    "            \n",
    "            # switch to evaluate mode\n",
    "            net.eval()\n",
    "            \n",
    "            for i, (input, batch_cif_ids) in enumerate(val_loader):\n",
    "                prediction = net(input.cuda(non_blocking=True))\n",
    "                val_loss_MAE = torch.mean(torch.abs(target[batch_cif_ids].cuda(non_blocking=True) - prediction))*prediction.shape[-1]\n",
    "                val_loss_MSE = loss_func(prediction, target[batch_cif_ids].cuda(non_blocking=True))*prediction.shape[-1]\n",
    "            \n",
    "            for i, (input, batch_cif_ids) in enumerate(test_loader):\n",
    "                prediction = net(input.cuda(non_blocking=True))\n",
    "                test_loss_MAE = torch.mean(torch.abs(target[batch_cif_ids].cuda(non_blocking=True) - prediction))*prediction.shape[-1]\n",
    "                test_loss_MSE = loss_func(prediction, target[batch_cif_ids].cuda(non_blocking=True))*prediction.shape[-1]\n",
    "            \n",
    "            best_counter += 1\n",
    "            \n",
    "            if best_val_loss > val_loss_MSE:\n",
    "                best_val_loss = val_loss_MSE\n",
    "                best_counter = 0\n",
    "                best_state = {'epoch': epoch + 1,\n",
    "                              'state_dict': net.state_dict(),\n",
    "                              'best_mae_error': best_val_loss,\n",
    "                              'optimizer': optimizer.state_dict()}\n",
    "                \n",
    "                final_ans_val_MAE[idx_val,idx_test] = val_loss_MAE\n",
    "                final_ans_val_MSE[idx_val,idx_test] = val_loss_MSE\n",
    "                final_ans_test_MAE[idx_val,idx_test] = test_loss_MAE\n",
    "                final_ans_test_MSE[idx_val,idx_test] = test_loss_MSE\n",
    "                \n",
    "                filename = 'model_best_train_idx_val_' + str(idx_val) + '_idx_test_' + str(idx_test) + '.pth.tar'\n",
    "                torch.save(best_state, filename)\n",
    "            \n",
    "            if best_counter >= 50:\n",
    "                print('Exit due to converged')\n",
    "                break\n",
    "            \n",
    "            if val_loss_MSE != val_loss_MSE:\n",
    "                print('Exit due to NaN')\n",
    "                break\n",
    "\n",
    "np.savetxt('final_ans_val_MAE.txt', final_ans_val_MAE)\n",
    "np.savetxt('final_ans_val_MSE.txt', final_ans_val_MSE)\n",
    "np.savetxt('final_ans_test_MAE.txt', final_ans_test_MAE)\n",
    "np.savetxt('final_ans_test_MSE.txt', final_ans_test_MSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
