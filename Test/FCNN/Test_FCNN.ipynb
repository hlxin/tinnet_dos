{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f197fff4",
   "metadata": {},
   "source": [
    "Test the performance of pre-trained FCNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading module\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "from copy import deepcopy\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from ase.db import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "\n",
    "def get_train_val_test_loader(dataset,\n",
    "                              idx_validation=0,\n",
    "                              idx_test=None,\n",
    "                              collate_fn=default_collate,\n",
    "                              batch_size=64,\n",
    "                              num_workers=0,\n",
    "                              pin_memory=False,\n",
    "                              random_seed=None):\n",
    "    \n",
    "    indices = np.arange(len(dataset))[:-38]\n",
    "    tmp = np.arange(len(dataset))[-38:] # Last 38 images are pure metals\n",
    "    \n",
    "    if random_seed:\n",
    "        random.Random(random_seed).shuffle(indices)\n",
    "    else:\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    kfold = np.array_split(indices,10)\n",
    "    \n",
    "    kfold_val = deepcopy(kfold[idx_validation])\n",
    "    \n",
    "    try:\n",
    "        kfold_test = deepcopy(kfold[idx_test])\n",
    "    except:\n",
    "        kfold_test = []\n",
    "    \n",
    "    kfold_train = deepcopy([kfold[i]\n",
    "                            for i in range(0,10)\n",
    "                            if i != idx_validation and i != idx_test])\n",
    "    \n",
    "    kfold_train = np.array([item for sl in kfold_train for item in sl])\n",
    "    \n",
    "    kfold_train = np.concatenate((kfold_train,tmp))\n",
    "    \n",
    "    if random_seed:\n",
    "        random.Random(random_seed).shuffle(kfold_train)\n",
    "    else:\n",
    "        random.shuffle(kfold_train)\n",
    "    \n",
    "    val_sampler = SubsetRandomSampler(deepcopy(kfold_val))\n",
    "    test_sampler = SubsetRandomSampler(deepcopy(kfold_test))\n",
    "    train_sampler = SubsetRandomSampler(deepcopy(kfold_train))\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                              sampler=train_sampler,\n",
    "                              num_workers=num_workers,\n",
    "                              collate_fn=collate_fn,\n",
    "                              pin_memory=pin_memory)\n",
    "    \n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                            sampler=val_sampler,\n",
    "                            num_workers=num_workers,\n",
    "                            collate_fn=collate_fn,\n",
    "                            pin_memory=pin_memory)\n",
    "    \n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                             sampler=test_sampler,\n",
    "                             num_workers=num_workers,\n",
    "                             collate_fn=collate_fn,\n",
    "                             pin_memory=pin_memory)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112cf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_feature, n_h, h_fea_len, n_output):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc_in = nn.Linear(n_feature, h_fea_len)\n",
    "        self.fc_in_softplus = nn.Softplus()\n",
    "        if n_h > 1:\n",
    "            self.fcs = nn.ModuleList([nn.Linear(h_fea_len, h_fea_len)\n",
    "                                      for _ in range(n_h-1)])\n",
    "            self.softpluses = nn.ModuleList([nn.Softplus()\n",
    "                                             for _ in range(n_h-1)])\n",
    "        self.fc_out = nn.Linear(h_fea_len, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        crys_fea = self.fc_in(x)\n",
    "        crys_fea = self.fc_in_softplus(crys_fea)\n",
    "        \n",
    "        if hasattr(self, 'fcs') and hasattr(self, 'softpluses'):\n",
    "            for fc, softplus in zip(self.fcs, self.softpluses):\n",
    "                crys_fea = softplus(fc(crys_fea))\n",
    "        \n",
    "        out = self.fc_out(crys_fea)\n",
    "        out = torch.stack((out[:,0], torch.nn.functional.softplus(out[:,1]))).T\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7924dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance of pre-trained FCNN models\n",
    "check_ans_train_MAE = np.zeros((10,10))\n",
    "check_ans_train_MSE = np.zeros((10,10))\n",
    "check_ans_val_MAE = np.zeros((10,10))\n",
    "check_ans_val_MSE = np.zeros((10,10))\n",
    "check_ans_test_MAE = np.zeros((10,10))\n",
    "check_ans_test_MSE = np.zeros((10,10))\n",
    "\n",
    "for idx_val in range(8,9):\n",
    "    for idx_test in range(9,10):\n",
    "        \n",
    "        lr = 0.001050190043090246\n",
    "        n_h = 8\n",
    "        h_fea_len = 65\n",
    "        \n",
    "        random_seed = 1234    # reproducible\n",
    "        batch_size = 12500\n",
    "        num_workers = 0\n",
    "        weight_decay = 0.0001\n",
    "        \n",
    "        collate_fn = default_collate\n",
    "        best_val_loss = 1e10\n",
    "        best_counter = 0\n",
    "        \n",
    "        db = connect('../Database.db')\n",
    "        \n",
    "        d_cen = np.array([r['data']['d_cen'] for r in db.select()])\n",
    "        full_width = np.array([r['data']['full_width'] for r in db.select()])\n",
    "        target = np.stack((d_cen,full_width)).T\n",
    "\n",
    "        v2ds = np.array([r['data']['tabulated_v2ds'] for r in db.select()])\n",
    "        v2dd = np.array([r['data']['tabulated_v2dd'] for r in db.select()])\n",
    "        mulliken = np.array([r['data']['tabulated_mulliken'] for r in db.select()])\n",
    "        d_cen_inf = np.array([r['data']['tabulated_d_cen_inf'] for r in db.select()])\n",
    "        full_width_inf = np.array([r['data']['tabulated_full_width_inf'] for r in db.select()])\n",
    "        fea = np.stack((np.sum((v2ds + v2dd), axis=1), mulliken, d_cen_inf, full_width_inf**2.0/12.0)).T\n",
    "        \n",
    "        idx = np.arange(len(target))\n",
    "        \n",
    "        idx_1 = idx[:-38]\n",
    "        idx_2 = idx[-38:] # Last 38 images are pure metals\n",
    "        \n",
    "        num = int(len(idx_1)*1.00)\n",
    "        np.random.seed(12345)\n",
    "        np.random.shuffle(idx_1)\n",
    "        \n",
    "        idx_1 = idx_1[0:num]\n",
    "        \n",
    "        idx = np.sort(np.concatenate((idx_1,idx_2)))\n",
    "        \n",
    "        np.savetxt('index.txt', idx)\n",
    "        \n",
    "        target = np.array([target[i] for i in idx])\n",
    "        \n",
    "        fea = np.array([fea[i] for i in idx])\n",
    "        \n",
    "        target = Variable(torch.Tensor(target))\n",
    "        fea = Variable(torch.Tensor(fea))\n",
    "        \n",
    "        name_images = np.arange(len(fea))\n",
    "        \n",
    "        dataset = [(torch.Tensor(fea[i]),\n",
    "                    name_images[i])\n",
    "                   for i in range(len(fea))]\n",
    "        \n",
    "        train_loader, val_loader, test_loader =\\\n",
    "            get_train_val_test_loader(dataset=dataset,\n",
    "                                      collate_fn=collate_fn,\n",
    "                                      batch_size=batch_size,\n",
    "                                      idx_validation=idx_val,\n",
    "                                      idx_test=idx_test,\n",
    "                                      num_workers=num_workers,\n",
    "                                      pin_memory=torch.cuda.is_available(),\n",
    "                                      random_seed=random_seed)\n",
    "        \n",
    "        net = Net(n_feature=fea.shape[-1], n_h=n_h, h_fea_len=h_fea_len, n_output=2).cuda()\n",
    "        optimizer = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_func = nn.MSELoss()\n",
    "        \n",
    "        best_checkpoint = torch.load('model_best_train_idx_val_' + str(idx_val) + '_idx_test_' + str(idx_test) + '.pth.tar')\n",
    "        net.load_state_dict(best_checkpoint['state_dict'])\n",
    "        \n",
    "        # switch to evaluate mode\n",
    "        net.eval()\n",
    "        \n",
    "        for i, (input, batch_cif_ids) in enumerate(train_loader):\n",
    "            prediction = net(input.cuda(non_blocking=True))\n",
    "            train_loss_MAE = torch.mean(torch.abs(target[batch_cif_ids].cuda(non_blocking=True) - prediction))*prediction.shape[-1]\n",
    "            train_loss_MSE = loss_func(prediction, target[batch_cif_ids].cuda(non_blocking=True))*prediction.shape[-1]\n",
    "            print('Train loss MAE {loss:.4f}'.format(loss=train_loss_MAE))\n",
    "            print('Train loss MSE {loss:.4f}'.format(loss=train_loss_MSE))\n",
    "            \n",
    "            ans = np.column_stack((batch_cif_ids, target[batch_cif_ids].detach().numpy(), prediction.detach().cpu().numpy()))\n",
    "            np.savetxt('train_results_idx_val_' + str(idx_val) + '_idx_test_' + str(idx_test) + '.txt', ans)\n",
    "            \n",
    "            batch_cif_ids = batch_cif_ids.detach().numpy()\n",
    "            target_out = target.detach().numpy()\n",
    "            prediction = prediction.detach().cpu().numpy()\n",
    "            \n",
    "            with open('train_results_idx_val_' + str(idx_val) + '_idx_test_' + str(idx_test) + '.csv', 'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for cif_id, target_out, pred in zip(batch_cif_ids, target_out[batch_cif_ids], prediction):\n",
    "                    writer.writerow((cif_id, target_out[0], target_out[1], pred[0], pred[1]))\n",
    "        \n",
    "        for i, (input, batch_cif_ids) in enumerate(val_loader):\n",
    "            prediction = net(input.cuda(non_blocking=True))\n",
    "            val_loss_MAE = torch.mean(torch.abs(target[batch_cif_ids].cuda(non_blocking=True) - prediction))*prediction.shape[-1]\n",
    "            val_loss_MSE = loss_func(prediction, target[batch_cif_ids].cuda(non_blocking=True))*prediction.shape[-1]\n",
    "            print('Validation loss MAE {loss:.4f}'.format(loss=val_loss_MAE))\n",
    "            print('Validation loss MSE {loss:.4f}'.format(loss=val_loss_MSE))\n",
    "            \n",
    "            ans = np.column_stack((batch_cif_ids, target[batch_cif_ids].detach().numpy(), prediction.detach().cpu().numpy()))\n",
    "            np.savetxt('val_results_idx_val_' + str(idx_val) + '_idx_test_' + str(idx_test) + '.txt', ans)\n",
    "            \n",
    "            batch_cif_ids = batch_cif_ids.detach().numpy()\n",
    "            target_out = target.detach().numpy()\n",
    "            prediction = prediction.detach().cpu().numpy()\n",
    "            \n",
    "            with open('val_results_idx_val_' + str(idx_val) + '_idx_test_' + str(idx_test) + '.csv', 'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for cif_id, target_out, pred in zip(batch_cif_ids, target_out[batch_cif_ids], prediction):\n",
    "                    writer.writerow((cif_id, target_out[0], target_out[1], pred[0], pred[1]))\n",
    "        \n",
    "        for i, (input, batch_cif_ids) in enumerate(test_loader):\n",
    "            prediction = net(input.cuda(non_blocking=True))\n",
    "            test_loss_MAE = torch.mean(torch.abs(target[batch_cif_ids].cuda(non_blocking=True) - prediction))*prediction.shape[-1]\n",
    "            test_loss_MSE = loss_func(prediction, target[batch_cif_ids].cuda(non_blocking=True))*prediction.shape[-1]\n",
    "            print('Test loss MAE {loss:.4f}'.format(loss=test_loss_MAE))\n",
    "            print('Test loss MSE {loss:.4f}'.format(loss=test_loss_MSE))\n",
    "            \n",
    "            ans = np.column_stack((batch_cif_ids, target[batch_cif_ids].detach().numpy(), prediction.detach().cpu().numpy()))\n",
    "            np.savetxt('test_results_idx_val_' + str(idx_val) + '_idx_test_' + str(idx_test) + '.txt', ans)\n",
    "            \n",
    "            batch_cif_ids = batch_cif_ids.detach().numpy()\n",
    "            target_out = target.detach().numpy()\n",
    "            prediction = prediction.detach().cpu().numpy()\n",
    "            \n",
    "            with open('test_results_idx_val_' + str(idx_val) + '_idx_test_' + str(idx_test) + '.csv', 'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for cif_id, target_out, pred in zip(batch_cif_ids, target_out[batch_cif_ids], prediction):\n",
    "                    writer.writerow((cif_id, target_out[0], target_out[1], pred[0], pred[1]))\n",
    "        \n",
    "        check_ans_train_MAE[idx_test,idx_val] = train_loss_MAE\n",
    "        check_ans_train_MSE[idx_test,idx_val] = train_loss_MSE\n",
    "        check_ans_val_MAE[idx_test,idx_val] = val_loss_MAE\n",
    "        check_ans_val_MSE[idx_test,idx_val] = val_loss_MSE\n",
    "        check_ans_test_MAE[idx_test,idx_val] = test_loss_MAE\n",
    "        check_ans_test_MSE[idx_test,idx_val] = test_loss_MSE\n",
    "\n",
    "np.savetxt('check_ans_train_MAE.txt', check_ans_train_MAE)\n",
    "np.savetxt('check_ans_train_MSE.txt', check_ans_train_MSE)\n",
    "np.savetxt('check_ans_val_MAE.txt', check_ans_val_MAE)\n",
    "np.savetxt('check_ans_val_MSE.txt', check_ans_val_MSE)\n",
    "np.savetxt('check_ans_test_MAE.txt', check_ans_test_MAE)\n",
    "np.savetxt('check_ans_test_MSE.txt', check_ans_test_MSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
